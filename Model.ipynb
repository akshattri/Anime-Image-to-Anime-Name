{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b8e00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Normalize\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "data_dir = 'C:\\Aries\\Dataset'\n",
    "dataset = ImageFolder(data_dir+'/train', transform=transform)\n",
    "dataset_val = ImageFolder(data_dir+'/val', transform=transform)\n",
    "dataset_test = ImageFolder(data_dir+'/test', transform=transform)\n",
    "\n",
    "# print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/train\")\n",
    "\n",
    "# Define the data loaders\n",
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding = 1, stride = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding = 1, stride = 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding = 1, stride = 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding = 1, stride = 1)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=256 * 16 * 16, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=6)\n",
    "        \n",
    "        # Define the activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Define the max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Perform the forward pass through the convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten the output from the convolutional layers\n",
    "        x = x.view(-1, 256 * 16 * 16)\n",
    "        \n",
    "        # Perform the forward pass through the fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the model and the optimizer\n",
    "model = MyCNN(num_classes=6)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9c37966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.8937,        Train Acc: 0.6429, Val Loss: 0.7521, Val Acc: 0.6878\n",
      "Epoch [2/10], Train Loss: 0.6225,        Train Acc: 0.7613, Val Loss: 0.6148, Val Acc: 0.7630\n",
      "Epoch [3/10], Train Loss: 0.5143,        Train Acc: 0.8077, Val Loss: 0.6734, Val Acc: 0.7643\n",
      "Epoch [4/10], Train Loss: 0.3943,        Train Acc: 0.8591, Val Loss: 0.6593, Val Acc: 0.7812\n",
      "Epoch [5/10], Train Loss: 0.2244,        Train Acc: 0.9204, Val Loss: 0.7884, Val Acc: 0.7850\n",
      "Epoch [6/10], Train Loss: 0.1355,        Train Acc: 0.9550, Val Loss: 1.0219, Val Acc: 0.7793\n",
      "Epoch [7/10], Train Loss: 0.1165,        Train Acc: 0.9625, Val Loss: 1.0254, Val Acc: 0.7900\n",
      "Epoch [8/10], Train Loss: 0.0445,        Train Acc: 0.9849, Val Loss: 1.4399, Val Acc: 0.7875\n",
      "Epoch [9/10], Train Loss: 0.0516,        Train Acc: 0.9820, Val Loss: 1.4595, Val Acc: 0.7699\n",
      "Epoch [10/10], Train Loss: 0.0739,        Train Acc: 0.9796, Val Loss: 1.5040, Val Acc: 0.7705\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize variables for tracking loss and accuracy\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    \n",
    "    # Iterate over the training data\n",
    "    for images, labels in train_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the training loss and accuracy\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Compute the average training loss and accuracy\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = train_correct / len(train_loader.dataset)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize variables for tracking loss and accuracy\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    \n",
    "    # Iterate over the validation data\n",
    "    for images, labels in val_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # Update the validation loss and accuracy\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Compute the average validation loss and accuracy\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = val_correct / len(val_loader.dataset)\n",
    "    \n",
    "    # Print the training and validation loss and accuracy\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f},\\\n",
    "        Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save the weights to Google Drive\n",
    "    torch.save(model.state_dict(), 'my_model1_final.pth')\n",
    "    file_name = f'weights_final_epoch_{epoch}.pth'\n",
    "    save_path = 'C:\\Aries\\Weights' + file_name\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    # Saving the Model\n",
    "    model_path = 'C:\\Aries\\my_model2_final.pth'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff8e3a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4336, Test Accuracy: 0.7732\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "# import cv2\n",
    "import os\n",
    "\n",
    "# Define the path to the data directory\n",
    "data_dir = 'C:\\Aries\\Dataset'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize the model\n",
    "model = MyCNN(num_classes = 6)\n",
    "\n",
    "# Load the trained weights into the model\n",
    "model.load_state_dict(torch.load(\"C:\\Aries\\Weightsweights_final_epoch_9.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize variables for tracking loss and accuracy\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "\n",
    "# Iterate over the test data\n",
    "for images, labels in test_loader:\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "        \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, labels)\n",
    "        \n",
    "    # Update the test loss and accuracy\n",
    "    test_loss += loss.item() * images.size(0)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute the average test loss and accuracy\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_acc = test_correct / len(test_loader.dataset)\n",
    "\n",
    "# Print the test loss and accuracy\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b1c9b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: Your Name\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "filename = '1.jpg'\n",
    "image = Image.open(filename)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "image = transform(image)\n",
    "\n",
    "# Add a batch dimension to the image\n",
    "image = image.unsqueeze(0)\n",
    "model = MyCNN(num_classes = 6)\n",
    "\n",
    "# Load the trained weights into the model\n",
    "model.load_state_dict(torch.load(\"C:\\Aries\\Weightsweights_final_epoch_7.pth\"))\n",
    "# Get the predicted class probabilities\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "\n",
    "# Convert the predicted class probabilities to class labels\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Print the predicted class label\n",
    "print(\"Predicted class label:\", classes[predicted.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139a835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
